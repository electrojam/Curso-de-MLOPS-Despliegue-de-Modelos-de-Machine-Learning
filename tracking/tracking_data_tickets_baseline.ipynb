{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mdurango/Proyect/Mlops-platzi/.venv/lib/python3.9/site-packages/pydantic/_internal/_fields.py:149: UserWarning: Field \"model_server_url\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/Users/mdurango/Proyect/Mlops-platzi/.venv/lib/python3.9/site-packages/pydantic/_internal/_config.py:318: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import mlflow\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TicketProcessor: \n",
    "    def __init__(self,data_path: str): \n",
    "\n",
    "        self.data_path = data_path\n",
    "        self.vectorizer = TfidfVectorizer()\n",
    "        \n",
    "    def read_data(self, file_name: str): \n",
    "        self.data_tickets = pd.read_csv(os.path.join(self.data_path, file_name))\n",
    "        return self.data_tickets\n",
    "    \n",
    "    def feature_extraction(self,text_column: str, target_column = \"categoria_producto_servicio_encoded\"): \n",
    "       self.vectorizer.fit(self.data_tickets[text_column])\n",
    "       self.X = self.vectorizer.transform(self.data_tickets[text_column])\n",
    "       self.y = self.data_tickets[target_column]\n",
    "       return self.X, self.y\n",
    "    \n",
    "    def split_data(self,test_size = 0.2, random_state = 42): \n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size = test_size, random_state = random_state)\n",
    "        \n",
    "        return self.X_train, self.X_test, self.y_train, self.y_test\n",
    "    \n",
    "    def read_labels_dict(self, file_name: str): \n",
    "        file_path = os.path.join(self.data_path, file_name)\n",
    "        with open(file_path, \"r\") as f: \n",
    "            self.labels_dict = json.load(f) \n",
    "        return self.labels_dict\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 60)\t0.3478490927580123\n",
      "  (0, 53)\t0.3478490927580123\n",
      "  (0, 48)\t0.3478490927580123\n",
      "  (0, 39)\t0.3478490927580123\n",
      "  (0, 38)\t0.3478490927580123\n",
      "  (0, 23)\t0.3478490927580123\n",
      "  (0, 20)\t0.3478490927580123\n",
      "  (0, 14)\t0.17890799126763965\n",
      "  (0, 2)\t0.3478490927580123\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "class TicketClassification:\n",
    "    def __init__(self, set_experiment_name: str = \"tickets_classification\"): \n",
    "\n",
    "        mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "        mlflow.set_experiment(set_experiment_name)\n",
    "        self.ticket_processor =  TicketProcessor(data_path = \"data/data_processed\")\n",
    "        self.data_ticket = self.ticket_processor.read_data(file_name = \"tickets_servicio_processed.csv\")\n",
    "        #print(self.data_ticket.shape)\n",
    "        self.X, self.y = self.ticket_processor.feature_extraction(text_column = \"processed_text\")\n",
    "        #print(self.X.shape)\n",
    "        print(len(self.ticket_processor.vectorizer.vocabulary_))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    TicketClassification()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-curso-py3.9",
   "language": "python",
   "name": "mlops-curso-py3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

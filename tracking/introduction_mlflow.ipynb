{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:pink\"> Seguimiento de Experimentos con MLflow</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.WARN)\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como habíamos mencionado en la intro del tracking experiment tiene muchas ventajas y es una de las mejores prácticas que podemos implementar en nuestro flujo de trabajo. En este notebook vamos a ver como podemos hacer tracking de nuestros experimentos con mlflow con diferentes modos de uso, es bueno que tengas en cuenta las diferentes opciones que te ofrece mlflow para hacer tracking de tus experimentos. Si esto te interesa tanto como a mí: "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"https://pbs.twimg.com/media/FURj-YsXoAAoXGo.jpg\" alt=\"Descripción de la imagen\" width=\"200\" />\n",
    "</div>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escenario 1: mlflow en localhost\n",
    "\n",
    "\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"https://mlflow.org/docs/latest/_images/scenario_1.png\" alt=\"Descripción de la imagen\" width=\"300\" />\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta es la forma más común de ejecutar MLflow, en este caso, MLflow se ejecuta en el mismo host donde se ejecuta el código de Python. Para ejecutar MLflow en localhost, simplemente ejecuta el siguiente comando en la línea de comandos:\n",
    "\n",
    "```bash\n",
    "mlflow ui\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo anterior iniciará un servidor web de MLflow en el puerto 5000 (por defecto). Para acceder a la interfaz de usuario de MLflow, abre http://localhost:5000 en tu navegador. Si presentas problemas con el puerto puedes especificar otro puerto ejecutando el comando \n",
    "```bash\n",
    "mlflow ui --port\n",
    "```\n",
    "\n",
    "También podremos crear una carpeta de forma local e indicarle a mlflow que lo fijamos como *_set_tracking_uri_*\n",
    "En la celda a continuación te enseñaré cómo hacerlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"tracking URI: '{mlflow.get_tracking_uri()}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"Experimento_1\")\n",
    "\n",
    "with mlflow.start_run(run_name = \"example_1\"):\n",
    "\n",
    "    X,y = load_iris(return_X_y= True)\n",
    "    params = {\"C\": 0.1, \"random_state\": 42}\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    lr = LogisticRegression(**params).fit(X, y)\n",
    "    y_pred = lr.predict(X)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy_score(y, y_pred))\n",
    "    mlflow.sklearn.log_model(lr, artifact_path=\"models\")\n",
    "    print(f\"default artifacts URI: '{mlflow.get_artifact_uri()}'\")\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Folder diferente a mlruns, se puede? Si, puedes crear una carpeta y especificarle a mlflow que lo fijamos como *_set_tracking_uri_*\n",
    ". Para abrir el tracking folder en la termina, debemos especificar el path de la carpeta que creamos y ejecutar el siguiente comando:\n",
    "\n",
    "mlflow ui --backend-store-uri file:////ruta_de_acceso_a_la_carpeta\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"Experimento_2\")\n",
    "mlflow.set_tracking_uri(\"/Users/mdurango/Proyect/Mlops-platzi/tracking/experiment_ml\")\n",
    "\n",
    "with mlflow.start_run(run_name = \"example_1\"):\n",
    "\n",
    "    X,y = load_iris(return_X_y= True)\n",
    "    params = {\"C\": 0.1, \"random_state\": 42}\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    lr = LogisticRegression(**params).fit(X, y)\n",
    "    y_pred = lr.predict(X)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy_score(y, y_pred))\n",
    "    mlflow.sklearn.log_model(lr, artifact_path=\"models\")\n",
    "    print(f\"default artifacts URI: '{mlflow.get_artifact_uri()}'\")\n",
    "\n",
    "# en la terminal vamos a estar a nivel de la carpeta donde se encuentra el archivo con los runs de mlflow   \n",
    "# mlflow ui --backend-store-uri file:////Users/mdurango/Proyect/Mlops-platzi/tracking/experiment_ml"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escenario 2: MLflow en localhost con SQLite\n",
    "\n",
    "Muchos usuarios también ejecutan MLflow en sus máquinas locales con una base de datos compatible con SQLAlchemy : SQLite . En este caso, los artefactos se almacenan en el ./mlrunsdirectorio local y las entidades de MLflow se insertan en un archivo de base de datos SQLite mlruns.db. Es bastante similar al escenario 1, pero usamos como back a sqlite. En lo personal adora los dos escenarios, sin embargo, también podemos usar un bucket en aws como back. Más adelante lo veremos. \n",
    "\n",
    "Para abrir el tracking folder con db como back, ejecutamos lo siguiente:\n",
    "\n",
    "mlflow ui --backend-store-uri sqlite:///backend.db\n",
    "\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"https://mlflow.org/docs/latest/_images/scenario_2.png\" alt=\"Descripción de la imagen\" width=\"300\" />\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"sqlite:///backend.db\")\n",
    "mlflow.set_experiment(\"Experimento_3\")\n",
    "\n",
    "with mlflow.start_run(run_name = \"example_1\"):\n",
    "\n",
    "    X,y = load_iris(return_X_y= True)\n",
    "    params = {\"C\": 0.1, \"random_state\": 42}\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    lr = LogisticRegression(**params).fit(X, y)\n",
    "    y_pred = lr.predict(X)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy_score(y, y_pred))\n",
    "    mlflow.sklearn.log_model(lr, artifact_path=\"models\")\n",
    "    print(f\"default artifacts URI: '{mlflow.get_artifact_uri()}'\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escenario 3: MLflow con servidor de seguimiento remoto, backend y almacenes de artefactos\n",
    "\n",
    "MLflow también admite arquitecturas distribuidas, donde el servidor de seguimiento, el almacén backend y el almacén de artefactos residen en hosts remotos. Este escenario de ejemplo muestra una arquitectura con un servidor de seguimiento de MLflow remoto, una base de datos de Postgres para el almacenamiento de entidades backend y un depósito de S3 para el almacenamiento de artefactos. Con este escensario se puede compartir el proyecto entre varios dddata scientist o machine learning engineers. \n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"https://mlflow.org/docs/latest/_images/scenario_4.png\" alt=\"Descripción de la imagen\" width=\"400\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "\n",
    "Setup escenario 1: \n",
    "\n",
    "* tracking server: no\n",
    "* backend: local\n",
    "* artifacts y metadata: local\n",
    "\n",
    "Setup escenario 2:\n",
    "\n",
    "* tracking server: sí, sqlite como local server \n",
    "* backend store: sqlite database\n",
    "* artifacts store: local filessystem\n",
    "\n",
    "Setup escenario 3:\n",
    "\n",
    "* tracking server: sí, remote server (EC2)\n",
    "* backend store: Postgres database\n",
    "* artifacts store: S3 bucket\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-curso-py3.9",
   "language": "python",
   "name": "mlops-curso-py3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
